@misc{NgIRL,
  author = {Ng, Andrew Y. and Russell, Stuart J.},
  booktitle = {ICML},
  date = {2002-11-26},
  pages = {663-670},
  title = {Algorithms for Inverse Reinforcement Learning.},
  url = {http://dblp.uni-trier.de/db/conf/icml/icml2000.html#NgR00},
  year = 2000
}

@inproceedings{Ziebart2008,
  author = {Ziebart, Brian D. and Maas, Andrew L. and Bagnell, J. Andrew and Dey, Anind K.},
  booktitle = {AAAI},
  isbn = {978-1-57735-368-3},
  keywords = {dblp},
  pages = {1433-1438},
  publisher = {AAAI Press},
  title = {Maximum Entropy Inverse Reinforcement Learning.},
  url = {http://dblp.uni-trier.de/db/conf/aaai/aaai2008.html#ZiebartMBD08},
  year = 2008
}
@misc{softQlearning,
    title={Reinforcement Learning with Deep Energy-Based Policies}, 
    author={Tuomas Haarnoja and Haoran Tang and Pieter Abbeel and Sergey Levine},
    year={2017},
    eprint={1702.08165},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@article{SuttonTD,
author = {Sutton, Richard S.},
title = {Learning to Predict by the Methods of Temporal Differences},
year = {1988},
issue_date = {August 1988},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {3},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1023/A:1022633531479},
doi = {10.1023/A:1022633531479},
abstract = {This article introduces a class of incremental learning procedures specialized for prediction – that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage.},
journal = {Mach. Learn.},
month = {aug},
pages = {9-44},
numpages = {36},
keywords = {credit assignment, connectionism, prediction, evaluation functions, Incremental learning}
}
@misc{SARSA,
  address = {Cambridge, England},
  author = {Rummery, G. A. and Niranjan, M.},
  institution = {Cambridge University Engineering Department},
  keywords = {nn},
  number = {TR 166},
  priority = {2},
  title = {On-Line {Q}-Learning Using Connectionist Systems},
  year = 1994
}
@misc{LevineRLasInf,
      title={Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review}, 
      author={Sergey Levine},
      year={2018},
      eprint={1805.00909},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Yang2017,
	year = 2017,
	month = {nov},
	publisher = {Informa {UK} Limited},
	volume = {18},
	number = {1},
	pages = {972 - 976},
	author = {Xiufeng Yang and Jinzhe Zhang and Kazuki Yoshizoe and Kei Terayama and Koji Tsuda},
	title = {{ChemTS}: an efficient python library for de novo molecular generation}, 
	journal = {Science and Technology of Advanced Materials}
}
@misc{olivecrona2017molecular,
      title={Molecular De Novo Design through Deep Reinforcement Learning}, 
      author={Marcus Olivecrona and Thomas Blaschke and Ola Engkvist and Hongming Chen},
      year={2017},
      eprint={1704.07555},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@inproceedings{FinnGCL,
  author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle = {ICML},
  keywords = {dblp},
  pages = {49-58},
  publisher = {JMLR.org},
  series = {JMLR Workshop and Conference Proceedings},
  title = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization.},
  url = {http://dblp.uni-trier.de/db/conf/icml/icml2016.html#FinnLA16},
  volume = 48,
  year = 2016
}
@article{GraphOpt,
  added-at = {2020-07-20T00:00:00.000+0200},
  author = {Trivedi, Rakshit and Yang, Jiachen and Zha, Hongyuan},
  biburl = {https://www.bibsonomy.org/bibtex/28f6359a96da094add27998cbbeb64836/dblp},
  ee = {https://arxiv.org/abs/2007.03619},
  interhash = {4c9e9ebb5be97f05334f9ba6f13ed009},
  intrahash = {8f6359a96da094add27998cbbeb64836},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2020-07-24T00:28:21.000+0200},
  title = {GraphOpt: Learning Optimization Models of Graph Formation.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr2007.html#abs-2007-03619},
  volume = {abs/2007.03619},
  year = 2020
}
@inproceedings{NerveNet,
  added-at = {2019-07-25T00:00:00.000+0200},
  author = {Wang, Tingwu and Liao, Renjie and Ba, Jimmy and Fidler, Sanja},
  biburl = {https://www.bibsonomy.org/bibtex/27094e296a3041c368a28f2f65ebfc9b8/dblp},
  booktitle = {ICLR (Poster)},
  crossref = {conf/iclr/2018},
  ee = {https://openreview.net/forum?id=S1sqHMZCb},
  interhash = {2798f33fac352cc3b0688e8eb6cb8c00},
  intrahash = {7094e296a3041c368a28f2f65ebfc9b8},
  keywords = {dblp},
  publisher = {OpenReview.net},
  timestamp = {2019-07-26T11:43:51.000+0200},
  title = {NerveNet: Learning Structured Policy with Graph Neural Networks.},
  url = {http://dblp.uni-trier.de/db/conf/iclr/iclr2018.html#WangLBF18},
  year = 2018
}
@article{UnivApproxNN,
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  doi = {http://dx.doi.org/10.1016/0893-6080(89)90020-8},
  journal = {Neural Networks },
  keywords = {ma-zehe neuralnet},
  number = 5,
  pages = {359 - 366},
  title = {Multilayer feedforward networks are universal approximators },
  url = {http://www.sciencedirect.com/science/article/pii/0893608089900208},
  volume = 2,
  year = 1989
}
@misc{GPT,
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  keywords = {final thema:transformer},
  title = {Improving language understanding by generative pre-training},
  year = 2018
}
@misc{nlpTranslation,
  title={Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation}, 
  author={Yonghui Wu and Mike Schuster and Zhifeng Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and Maxim Krikun and Yuan Cao and Qin Gao and Klaus Macherey and Jeff Klingner and Apurva Shah and Melvin Johnson and Xiaobing Liu and Łukasz Kaiser and Stephan Gouws and Yoshikiyo Kato and Taku Kudo and Hideto Kazawa and Keith Stevens and George Kurian and Nishant Patil and Wei Wang and Cliff Young and Jason Smith and Jason Riesa and Alex Rudnick and Oriol Vinyals and Greg Corrado and Macduff Hughes and Jeffrey Dean},
  year={2016},
  eprint={1609.08144},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
@article{PolyakAvg,
author = {Polyak, Boris},
year = {1991},
month = {01},
pages = {937-946},
title = {New method of stochastic approximation type},
volume = {7},
journal = {Autom. Remote Control}
}
@inproceedings{perDecision,
author = {Precup, Doina and Sutton, Richard S. and Singh, Satinder P.},
title = {Eligibility Traces for Off-Policy Policy Evaluation},
year = {2000},
isbn = {1558607072},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
pages = {759-766},
numpages = {8},
series = {ICML '00}
}
@article{QlearningWatkins1992,
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  doi = {10.1007/BF00992698},
  journal = {Machine Learning},
  keywords = {DRLAlgoComparison q-learning reinforcement_learning},
  month = may,
  number = 3,
  pages = {279--292},
  title = {Q-learning},
  url = {https://doi.org/10.1007/BF00992698},
  volume = 8,
  year = 1992
}
@misc{DQN,
      title={Playing Atari with Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
      year={2013},
      eprint={1312.5602},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{MPNNs,
    title={Neural Message Passing for Quantum Chemistry}, 
    author={Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
    year={2017},
    eprint={1704.01212},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{GPT2020,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{SVMs,
  author = {Cortes, Corinna and Vapnik, Vladimir},
  journal = {Machine Learning},
  keywords = {awm2011 svm},
  number = 3,
  pages = {273-297},
  title = {Support-Vector Networks.},
  url = {http://dblp.uni-trier.de/db/journals/ml/ml20.html#CortesV95},
  volume = 20,
  year = 1995
}
@article{journals/bioinformatics/BeumingSNMW05,
  author = {Beuming, Thijs and Skrabanek, Lucy and Niv, Masha Y. and Mukherjee, Piali and Weinstein, Harel},
  journal = {Bioinform.},
  keywords = {dblp},
  number = 6,
  pages = {827-828},
  title = {PDZBase: a protein?Cprotein interaction database for PDZ-domains.},
  url = {http://dblp.uni-trier.de/db/journals/bioinformatics/bioinformatics21.html#BeumingSNMW05},
  volume = 21,
  year = 2005
}
@article{REINFORCE,
  author = {Williams, R. J.},
  journal = {Machine Learning},
  keywords = {daanbib},
  pages = {229--256},
  priority = {2},
  title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  volume = 8,
  year = 1992
}
@misc{BERT,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{NSTGatys,
    title={A Neural Algorithm of Artistic Style}, 
    author={Leon A. Gatys and Alexander S. Ecker and Matthias Bethge},
    year={2015},
    eprint={1508.06576},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@misc{node2vec,
    title={node2vec: Scalable Feature Learning for Networks}, 
    author={Aditya Grover and Jure Leskovec},
    year={2016},
    eprint={1607.00653},
    archivePrefix={arXiv},
    primaryClass={cs.SI}
}
@inproceedings{DeepWalk,
	doi = {10.1145/2623330.2623732},
	url = {https://doi.org/10.1145%2F2623330.2623732},
	year = 2014,
	month = {aug},
	publisher = {{ACM}},
	author = {Bryan Perozzi and Rami Al-Rfou and Steven Skiena},
	title = {{DeepWalk}}, 
	booktitle = {Proceedings of the 20th {ACM} {SIGKDD} international conference on Knowledge discovery and data mining}
}
@inproceedings{SocialNets,
  title={Aligning Users across Social Networks Using Network Embedding},
  author={Li Liu and William Kwok-Wai Cheung and Xin Li and Lejian Liao},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:8770300}
}
@article{Recommender,
	doi = {10.1145/3285029},
	url = {https://doi.org/10.1145%2F3285029},
	year = 2019,
	month = {feb},
	publisher = {Association for Computing Machinery ({ACM})},
	volume = {52},
	number = {1},
	pages = {1--38},
	author = {Shuai Zhang and Lina Yao and Aixin Sun and Yi Tay},
	title = {Deep Learning Based Recommender System}, 
	journal = {{ACM} Computing Surveys}
}
@misc{goodfellow2014generative,
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  keywords = {RP2},
  note = {cite arxiv:1406.2661},
  title = {Generative Adversarial Networks},
  url = {http://arxiv.org/abs/1406.2661},
  year = 2014
}
@misc{VAEs,
    title={Auto-Encoding Variational Bayes}, 
    author={Diederik P Kingma and Max Welling},
    year={2022},
    eprint={1312.6114},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@misc{VGAE,
      title={Variational Graph Auto-Encoders}, 
      author={Thomas N. Kipf and Max Welling},
      year={2016},
      eprint={1611.07308},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{VGAEDisease,
      title={Towards Probabilistic Generative Models Harnessing Graph Neural Networks for Disease-Gene Prediction}, 
      author={Vikash Singh and Pietro Lio'},
      year={2019},
      eprint={1907.05628},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{langmodelsSurvey,
  title={A Survey of Large Language Models}, 
  author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
  year={2023},
  eprint={2303.18223},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
@inproceedings{transformers,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  biburl = {https://www.bibsonomy.org/bibtex/293fc8b1ceffe70343245d29fcf4d8efa/dblp},
  booktitle = {NIPS},
  editor = {Guyon, Isabelle and von Luxburg, Ulrike and Bengio, Samy and Wallach, Hanna M. and Fergus, Rob and Vishwanathan, S. V. N. and Garnett, Roman},
  ee = {http://papers.nips.cc/paper/7181-attention-is-all-you-need},
  keywords = {dblp},
  pages = {5998-6008},
  title = {Attention is All you Need.},
  url = {http://dblp.uni-trier.de/db/conf/nips/nips2017.html#VaswaniSPUJGKP17},
  year = 2017
}
@article{backprop,
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  journal = {Nature},
  keywords = {deeplearning ma-zehe neuralnet},
  month = oct,
  number = 6088,
  pages = {533--536},
  title = {Learning representations by back-propagating errors},
  url = {http://dx.doi.org/10.1038/323533a0},
  volume = 323,
  year = 1986
}
@incollection{PyTorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}
@inproceedings{tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}
@article{perceptron,
  author = {Rosenblatt, F.},
  doi = {10.1037/h0042519},
  journal = {Psychological Review},
  keywords = {imported},
  number = 6,
  pages = {386--408},
  title = {{The perceptron: A probabilistic model for information storage and organization in the brain.}},
  url = {http://dx.doi.org/10.1037/h0042519},
  volume = 65,
  year = 1958
}
@misc{textCNN,
  author = {Kim, Yoon},
  keywords = {classification cnn nlp seminar sentence ss2018 thema thema:cnn_kim},
  note = {cite arxiv:1408.5882Comment: To appear in EMNLP 2014},
  title = {Convolutional Neural Networks for Sentence Classification},
  url = {http://arxiv.org/abs/1408.5882},
  year = 2014
}
@misc{SentimentRNN,
  author = {Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher},
  keywords = {sentiment_analysis word_vectors related_works},
  title = {Learning word vectors for sentiment analysis},
  url = {http://dl.acm.org/citation.cfm?id=2002472.2002491},
  year = 2011
}
@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}
@inproceedings{alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}
@article{CNNsLecun,
  author = {LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  doi = {10.1109/5.726791},
  journal = {Proceedings of the IEEE},
  number = 11,
  pages = {2278-2324},
  timestamp = {2019-01-05T14:54:07.000+0100},
  title = {Gradient-based learning applied to document recognition},
  volume = 86,
  year = 1998
}
@article{ScarselliGNN,
  author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  doi = {10.1109/TNN.2008.2005605},
  journal = {IEEE Transactions on Neural Networks (TNN)},
  keywords = {},
  number = 1,
  pages = {61--80},
  publisher = {IEEE},
  timestamp = {2021-06-20T23:48:07.000+0200},
  title = {{The Graph Neural Network Model}},
  volume = 20,
  year = 2009
}
@article{Cora,
  added-at = {2011-05-25T00:00:00.000+0200},
  author = {McCallum, Andrew and Nigam, Kamal and Rennie, Jason and Seymore, Kristie},
  biburl = {https://www.bibsonomy.org/bibtex/2a5ab85f97cb61095e3c89c88220d4b15/dblp},
  ee = {http://dx.doi.org/10.1023/A:1009953814988},
  interhash = {d744a2c1477ab90faad895d6e236d5c0},
  intrahash = {a5ab85f97cb61095e3c89c88220d4b15},
  journal = {Inf. Retr.},
  keywords = {dblp},
  number = 2,
  pages = {127-163},
  timestamp = {2011-05-26T11:37:49.000+0200},
  title = {Automating the Construction of Internet Portals with Machine Learning.},
  url = {http://dblp.uni-trier.de/db/journals/ir/ir3.html#McCallumNRS00},
  volume = 3,
  year = 2000
}
@inproceedings{CiteSeer,
  abstract = {We present CifeSeer: an autonomous citation indexing system which indexes academic literature in electronic format (e.g. Postscript tiles on the Web). CiteSeer understands how to parse citations, identify citations to the same paper in different formats, and identify the context of citations in the body of articles. CiteSeer provides most of the advantages of traditional (manually constructed) citation indexes (e.g. the ISI citation indexes), including: literature retrieval by following citation links (e.g. by providing a list of papers that cite a given paper), the evaluation and ranking of papers, authors, journals, etc. based on the number of citations, and the identification of research trends.},
  added-at = {2016-05-26T14:43:23.000+0200},
  address = {New York, NY, USA},
  author = {Giles, C. Lee and Bollacker, Kurt D. and Lawrence, Steve},
  biburl = {https://www.bibsonomy.org/bibtex/25c296b356a2b6596e8772edc3b19b8c1/flint63},
  booktitle = {Proceedings of the Third ACM Conference on Digital Libraries, Pittsburgh, PA, USA},
  doi = {10.1145/276675.276685},
  file = {ACM Digital Library:1900-99/GilesBollackerLawrence98DL.pdf:PDF},
  groups = {public},
  interhash = {3c9d51d47b5cdeb783dd70010ed818c8},
  intrahash = {5c296b356a2b6596e8772edc3b19b8c1},
  isbn = {978-0-89791-965-4},
  keywords = {01624 acm paper ai web application publications information retrieval search},
  pages = {89--98},
  publisher = {ACM},
  timestamp = {2017-07-13T18:09:59.000+0200},
  title = {{CiteSeer}: An Automatic Citation Indexing System},
  username = {flint63},
  year = 1998
}
@INPROCEEDINGS{MuJoCo,
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={MuJoCo: A physics engine for model-based control}, 
  year={2012},
  volume={},
  number={},
  pages={5026-5033},
  doi={10.1109/IROS.2012.6386109}}

@misc{GCN,
      title={Semi-Supervised Classification with Graph Convolutional Networks}, 
      author={Thomas N. Kipf and Max Welling},
      year={2017},
      eprint={1609.02907},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{GATv2,
      title={How Attentive are Graph Attention Networks?}, 
      author={Shaked Brody and Uri Alon and Eran Yahav},
      year={2022},
      eprint={2105.14491},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{GAT,
    title={Graph Attention Networks}, 
    author={Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
    year={2018},
    eprint={1710.10903},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@misc{oversquashingGNN,
      title={How does over-squashing affect the power of GNNs?}, 
      author={Francesco Di Giovanni and T. Konstantin Rusch and Michael M. Bronstein and Andreea Deac and Marc Lackenby and Siddhartha Mishra and Petar Veličković},
      year={2023},
      eprint={2306.03589},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{HasseltDoubleQlearning,
      title={Deep Reinforcement Learning with Double Q-learning}, 
      author={Hado van Hasselt and Arthur Guez and David Silver},
      year={2015},
      eprint={1509.06461},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@InProceedings{SAC1,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf},
  url = 	 {https://proceedings.mlr.press/v80/haarnoja18b.html},
  abstract = 	 {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.}
}
@misc{SAC2,
      title={Soft Actor-Critic Algorithms and Applications}, 
      author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
      year={2019},
      eprint={1812.05905},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@book{Sutton1998,
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  biburl = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title = {Reinforcement Learning: An Introduction},
  url = {http://incompleteideas.net/book/the-book-2nd.html},
  year = {2018 }
}
@ARTICLE{JulierUT,
  author={Julier, S.J. and Uhlmann, J.K.},
  journal={Proceedings of the IEEE}, 
  title={Unscented filtering and nonlinear estimation}, 
  year={2004},
  volume={92},
  number={3},
  pages={401-422},
  doi={10.1109/JPROC.2003.823141}
}
@article{
BAGraphs,
author = {Albert-László Barabási  and Réka Albert },
title = {Emergence of Scaling in Random Networks},
journal = {Science},
volume = {286},
number = {5439},
pages = {509-512},
year = {1999},
doi = {10.1126/science.286.5439.509},
URL = {https://www.science.org/doi/abs/10.1126/science.286.5439.509},
eprint = {https://www.science.org/doi/pdf/10.1126/science.286.5439.509},
abstract = {Systems as diverse as genetic networks or the World Wide Web are best described as networks with complex topology. A common property of many large networks is that the vertex connectivities follow a scale-free power-law distribution. This feature was found to be a consequence of two generic mechanisms: (i) networks expand continuously by the addition of new vertices, and (ii) new vertices attach preferentially to sites that are already well connected. A model based on these two ingredients reproduces the observed stationary scale-free distributions, which indicates that the development of large networks is governed by robust self-organizing phenomena that go beyond the particulars of the individual systems.}
}
@misc{KStest3,
  title="Kolmogorov--Smirnov Test",
  bookTitle="The Concise Encyclopedia of Statistics",
  year="2008",
  publisher="Springer New York",
  address="New York, NY",
  pages="283--287",
  isbn="978-0-387-32833-1",
  doi="10.1007/978-0-387-32833-1_214",
  url="https://doi.org/10.1007/978-0-387-32833-1_214"
}
@inproceedings{Tsitsiklis,
 author = {Konda, Vijay and Tsitsiklis, John},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Solla and T. Leen and K. M\"{u}ller},
 pages = {},
 publisher = {MIT Press},
 title = {Actor-Critic Algorithms},
 url = {https://proceedings.neurips.cc/paper_files/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {12},
 year = {1999}
}
@misc{DeepMindGraphGen,
      title={Learning Deep Generative Models of Graphs}, 
      author={Yujia Li and Oriol Vinyals and Chris Dyer and Razvan Pascanu and Peter Battaglia},
      year={2018},
      eprint={1803.03324},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{GCNPolicyGraphGen,
      title={Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation}, 
      author={Jiaxuan You and Bowen Liu and Rex Ying and Vijay Pande and Jure Leskovec},
      year={2019},
      eprint={1806.02473},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{GraphRNN,
      title={GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models}, 
      author={Jiaxuan You and Rex Ying and Xiang Ren and William L. Hamilton and Jure Leskovec},
      year={2018},
      eprint={1802.08773},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{GraphRecAttNetGraphGen,
      title={Efficient Graph Generation with Graph Recurrent Attention Networks}, 
      author={Renjie Liao and Yujia Li and Yang Song and Shenlong Wang and Charlie Nash and William L. Hamilton and David Duvenaud and Raquel Urtasun and Richard S. Zemel},
      year={2020},
      eprint={1910.00760},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{NetGAN,
      title={NetGAN: Generating Graphs via Random Walks}, 
      author={Aleksandar Bojchevski and Oleksandr Shchur and Daniel Zügner and Stephan Günnemann},
      year={2018},
      eprint={1803.00816},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{RNNs,
      title={Recurrent Neural Networks (RNNs): A gentle Introduction and Overview}, 
      author={Robin M. Schmidt},
      year={2019},
      eprint={1912.05911},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Darvariu,
author = {Darvariu, Victor-Alexandru  and Hailes, Stephen  and Musolesi, Mirco },
title = {Planning spatial networks with Monte Carlo tree search},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
volume = {479},
number = {2269},
pages = {20220383},
year = {2023},
doi = {10.1098/rspa.2022.0383},
URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2022.0383},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.2022.0383}
,
abstract = { We tackle the problem of goal-directed graph construction: given a starting graph, finding a set of edges whose addition maximally improves a global objective function. This problem emerges in many transportation and infrastructure networks that are of critical importance to society. We identify two significant shortcomings of present reinforcement learning methods: their exclusive focus on topology to the detriment of spatial characteristics (which are known to influence the growth and density of links), as well as the rapid growth in the action spaces and costs of model training. Our formulation as a deterministic Markov decision process allows us to adopt the Monte Carlo tree search framework, an artificial intelligence decision-time planning method. We propose improvements over the standard upper confidence bounds for trees (UCT) algorithm for this family of problems that addresses their single-agent nature, the trade-off between the cost of edges and their contribution to the objective, and an action space linear in the number of nodes. Our approach yields substantial improvements over UCT for increasing the efficiency and attack resilience of synthetic networks and real-world Internet backbone and metro systems, while using a wall clock time budget similar to other search-based algorithms. We also demonstrate that our approach scales to significantly larger networks than previous reinforcement learning methods, since it does not require training a model. }
}